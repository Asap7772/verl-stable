{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['joint_prompt', 'paper1_prompt', 'paper2_prompt', 'no_context_prompt', 'abstracts', 'forum_id_1', 'forum_id_2', 'pair_id'],\n",
       "    num_rows: 99997\n",
       "})"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datasets\n",
    "\n",
    "ds = datasets.load_dataset('joyheyueya/250428_abstract_pair', split='train')\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'joint_prompt': 'Your task is to identify and elaborate on an insight that only becomes apparent by combining information from both documents together—i.e., an insight that has high relevance when treating the documents jointly but low relevance if you were to consider each document alone. Write the insight as a standalone statement that does not reference the original texts or use terms like \"paper\" or \"document\". The insight should involve indirect connections or intermediate reasoning steps, such as linking cause and effect through a shared variable or mechanism. Here are some examples: Let A = magnesium — either dietary or internal to the body. Implicitly refers, inmost cases, to quantity of magnesium. Let M = migraine headache. Let L = one or more intermediate physiological links.  -> means \\'can or might influence\\'. == means \\'equivalent in action\\' or \\'equivalent in mechanism\\' depending on whether it connects two drugs or two diseases. Paper 1:\\nStress and Type A behavior are associated with migraine.\\nPaper 2:\\nStress and Type A behavior lead to body loss of magnesium.\\nFrom these, we infer: Let B = Stress and Type A behavior. Let A = Magnesium levels. Let M = Migraines. From paper 1: B -> M. From Paper 2: B -> A. This suggests A may mediate the effect of B on M, i.e., A -> M. <insight>Low magnesium levels may be an intermediate link through which stress and Type A behavior contribute to migraines.</insight>\\nPaper 1:\\nExcessive vascular tone and reactivity may increase susceptibility to migraine.\\nPaper 2:\\nMagnesium can reduce vascular tone and reactivity.\\nWe define: A = Magnesium. L = Vascular tone and reactivity. M = Migraine. From these: (a) suggests L -> M. (b) suggests A -> L. Therefore, combining the two leads to: A -> M. <insight>Magnesium may help reduce migraine susceptibility by lowering vascular tone and reactivity.</insight>\\nPaper 1:\\nCalcium channel blockers have been used successfully in preventing migraine attacks.\\nPaper 2:\\nMagnesium is a natural calcium channel blocker.\\nWe define: A = Magnesium. B = Calcium channel blockers. M = Migraine. From these:(a) suggests B -> M (i.e., B prevents M). (b) suggests A == B (A is equivalent to B in mechanism). Therefore: A -> M. <insight>Magnesium may help prevent migraine attacks because it acts as a natural calcium channel blocker, similar to drugs already known to be effective.</insight>\\nPaper 1:\\nMachine learning models can capture and amplify biases present in data, leading to disparate test performance across social groups. To better understand, evaluate, and mitigate these biases, a deeper theoretical understanding of how model design choices and data distribution properties contribute to bias is needed. In this work, we contribute a precise analytical theory in the context of ridge regression, both with and without random projections, where the former models feedforward neural networks in a simplified regime. Our theory offers a unified and rigorous explanation of machine learning bias, providing insights into phenomena such as bias amplification and minority-group bias in various feature and parameter regimes. For example, we observe that there may be an optimal regularization penalty or training time to avoid bias amplification, and there can be differences in test error between groups that are not alleviated with increased parameterization. Importantly, our theoretical predictions align with  empirical observations reported in the literature on machine learning bias. We extensively empirically validate our theory on synthetic and semi-synthetic datasets.\\nPaper 2:\\nWe present a Chain-of-Action (CoA) framework for multimodal and retrieval-augmented Question-Answering (QA). Compared to the literature, CoA overcomes two major challenges of current QA applications: (i) unfaithful hallucination that is inconsistent with real-time or domain facts and (ii) weak reasoning performance over compositional information. Our key contribution is a novel reasoning-retrieval mechanism that decomposes a complex question into a reasoning chain via systematic prompting and pre-designed actions.  Methodologically, we propose three types of domain-adaptable `Plug-and-Play\\'  actions for retrieving real-time information from heterogeneous sources. We also propose a multi-reference faith score to verify conflicts in the answers.\\nIn addition, our system demonstrates that detecting the knowledge boundaries of LLMs can significantly reduce both LLM interaction frequency and tokens usage in QA tasks. Empirically, we exploit both public benchmarks and a Web3 case study to demonstrate the capability of CoA over other methods.\\nPut the insight between <insight> and </insight> tagsLet\\'s think step by step. ',\n",
       " 'paper1_prompt': 'Paper:\\nMachine learning models can capture and amplify biases present in data, leading to disparate test performance across social groups. To better understand, evaluate, and mitigate these biases, a deeper theoretical understanding of how model design choices and data distribution properties contribute to bias is needed. In this work, we contribute a precise analytical theory in the context of ridge regression, both with and without random projections, where the former models feedforward neural networks in a simplified regime. Our theory offers a unified and rigorous explanation of machine learning bias, providing insights into phenomena such as bias amplification and minority-group bias in various feature and parameter regimes. For example, we observe that there may be an optimal regularization penalty or training time to avoid bias amplification, and there can be differences in test error between groups that are not alleviated with increased parameterization. Importantly, our theoretical predictions align with  empirical observations reported in the literature on machine learning bias. We extensively empirically validate our theory on synthetic and semi-synthetic datasets.\\nYour task is to identify and elaborate on an insight from the paper. The insight should be self-contained. Write it in a way that doesn’t require referencing where it came from. Do not mention the word \"paper\" or \"document\". Let\\'s think step by step. ',\n",
       " 'paper2_prompt': 'Paper:\\nWe present a Chain-of-Action (CoA) framework for multimodal and retrieval-augmented Question-Answering (QA). Compared to the literature, CoA overcomes two major challenges of current QA applications: (i) unfaithful hallucination that is inconsistent with real-time or domain facts and (ii) weak reasoning performance over compositional information. Our key contribution is a novel reasoning-retrieval mechanism that decomposes a complex question into a reasoning chain via systematic prompting and pre-designed actions.  Methodologically, we propose three types of domain-adaptable `Plug-and-Play\\'  actions for retrieving real-time information from heterogeneous sources. We also propose a multi-reference faith score to verify conflicts in the answers.\\nIn addition, our system demonstrates that detecting the knowledge boundaries of LLMs can significantly reduce both LLM interaction frequency and tokens usage in QA tasks. Empirically, we exploit both public benchmarks and a Web3 case study to demonstrate the capability of CoA over other methods.\\nYour task is to identify and elaborate on an insight from the paper. The insight should be self-contained. Write it in a way that doesn’t require referencing where it came from. Do not mention the word \"paper\" or \"document\". Let\\'s think step by step. ',\n",
       " 'no_context_prompt': 'Give me an insight. ',\n",
       " 'abstracts': ['Machine learning models can capture and amplify biases present in data, leading to disparate test performance across social groups. To better understand, evaluate, and mitigate these biases, a deeper theoretical understanding of how model design choices and data distribution properties contribute to bias is needed. In this work, we contribute a precise analytical theory in the context of ridge regression, both with and without random projections, where the former models feedforward neural networks in a simplified regime. Our theory offers a unified and rigorous explanation of machine learning bias, providing insights into phenomena such as bias amplification and minority-group bias in various feature and parameter regimes. For example, we observe that there may be an optimal regularization penalty or training time to avoid bias amplification, and there can be differences in test error between groups that are not alleviated with increased parameterization. Importantly, our theoretical predictions align with  empirical observations reported in the literature on machine learning bias. We extensively empirically validate our theory on synthetic and semi-synthetic datasets.',\n",
       "  \"We present a Chain-of-Action (CoA) framework for multimodal and retrieval-augmented Question-Answering (QA). Compared to the literature, CoA overcomes two major challenges of current QA applications: (i) unfaithful hallucination that is inconsistent with real-time or domain facts and (ii) weak reasoning performance over compositional information. Our key contribution is a novel reasoning-retrieval mechanism that decomposes a complex question into a reasoning chain via systematic prompting and pre-designed actions.  Methodologically, we propose three types of domain-adaptable `Plug-and-Play'  actions for retrieving real-time information from heterogeneous sources. We also propose a multi-reference faith score to verify conflicts in the answers.\\nIn addition, our system demonstrates that detecting the knowledge boundaries of LLMs can significantly reduce both LLM interaction frequency and tokens usage in QA tasks. Empirically, we exploit both public benchmarks and a Web3 case study to demonstrate the capability of CoA over other methods.\"],\n",
       " 'forum_id_1': 'VoI4d6uhdr',\n",
       " 'forum_id_2': '1BdPHbuimc',\n",
       " 'pair_id': 'VoI4d6uhdr_1BdPHbuimc'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['paper1_prompt', 'paper2_prompt', 'no_context_prompt', 'abstracts', 'forum_id_1', 'forum_id_2', 'pair_id', 'data_source', 'prompt', 'ability', 'reward_model', 'extra_info'],\n",
       "    num_rows: 99997\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import Dict, Any, Optional\n",
    "import os\n",
    "def make_map_fn(split: str):\n",
    "    \"\"\"Create a mapping function to process dataset examples.\n",
    "\n",
    "    Args:\n",
    "        split: Dataset split name ('train' or 'test')\n",
    "\n",
    "    Returns:\n",
    "        Function that processes individual dataset examples\n",
    "    \"\"\"\n",
    "    def process_fn(example: Dict[str, Any], idx: int) -> Optional[Dict[str, Any]]:\n",
    "        question = example.pop('joint_prompt')\n",
    "        answer = '' # empty string (dummy)\n",
    "\n",
    "        data = {\n",
    "            \"data_source\": \"\",\n",
    "            \"prompt\": [{\n",
    "                \"role\": \"user\",\n",
    "                \"content\": question\n",
    "            }],\n",
    "            \"ability\": \"insight\",\n",
    "            \"reward_model\": {\n",
    "                \"style\": \"rule\",\n",
    "                \"ground_truth\": answer\n",
    "            },\n",
    "            \"extra_info\": {\n",
    "                'paper1_prompt': example['paper1_prompt'],\n",
    "                'paper2_prompt': example['paper2_prompt'],\n",
    "                'no_context_prompt': example['no_context_prompt'],\n",
    "                'abstracts': example['abstracts'],\n",
    "                'forum_id_1': example['forum_id_1'],\n",
    "                'forum_id_2': example['forum_id_2'],\n",
    "                'pair_id': example['pair_id'],\n",
    "                'split': split,\n",
    "                'index': idx\n",
    "            }\n",
    "        }\n",
    "        return data\n",
    "    return process_fn\n",
    "\n",
    "ds_train = ds.map(function=make_map_fn('train'), with_indices=True, num_proc=os.cpu_count())\n",
    "ds_test = ds.map(function=make_map_fn('test'), with_indices=True, num_proc=os.cpu_count())\n",
    "\n",
    "\n",
    "ds_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'abstracts': ['Machine learning models can capture and amplify biases present in data, leading to disparate test performance across social groups. To better understand, evaluate, and mitigate these biases, a deeper theoretical understanding of how model design choices and data distribution properties contribute to bias is needed. In this work, we contribute a precise analytical theory in the context of ridge regression, both with and without random projections, where the former models feedforward neural networks in a simplified regime. Our theory offers a unified and rigorous explanation of machine learning bias, providing insights into phenomena such as bias amplification and minority-group bias in various feature and parameter regimes. For example, we observe that there may be an optimal regularization penalty or training time to avoid bias amplification, and there can be differences in test error between groups that are not alleviated with increased parameterization. Importantly, our theoretical predictions align with  empirical observations reported in the literature on machine learning bias. We extensively empirically validate our theory on synthetic and semi-synthetic datasets.',\n",
       "  \"We present a Chain-of-Action (CoA) framework for multimodal and retrieval-augmented Question-Answering (QA). Compared to the literature, CoA overcomes two major challenges of current QA applications: (i) unfaithful hallucination that is inconsistent with real-time or domain facts and (ii) weak reasoning performance over compositional information. Our key contribution is a novel reasoning-retrieval mechanism that decomposes a complex question into a reasoning chain via systematic prompting and pre-designed actions.  Methodologically, we propose three types of domain-adaptable `Plug-and-Play'  actions for retrieving real-time information from heterogeneous sources. We also propose a multi-reference faith score to verify conflicts in the answers.\\nIn addition, our system demonstrates that detecting the knowledge boundaries of LLMs can significantly reduce both LLM interaction frequency and tokens usage in QA tasks. Empirically, we exploit both public benchmarks and a Web3 case study to demonstrate the capability of CoA over other methods.\"],\n",
       " 'forum_id_1': 'VoI4d6uhdr',\n",
       " 'forum_id_2': '1BdPHbuimc',\n",
       " 'index': 0,\n",
       " 'no_context_prompt': 'Give me an insight. ',\n",
       " 'pair_id': 'VoI4d6uhdr_1BdPHbuimc',\n",
       " 'paper1_prompt': 'Paper:\\nMachine learning models can capture and amplify biases present in data, leading to disparate test performance across social groups. To better understand, evaluate, and mitigate these biases, a deeper theoretical understanding of how model design choices and data distribution properties contribute to bias is needed. In this work, we contribute a precise analytical theory in the context of ridge regression, both with and without random projections, where the former models feedforward neural networks in a simplified regime. Our theory offers a unified and rigorous explanation of machine learning bias, providing insights into phenomena such as bias amplification and minority-group bias in various feature and parameter regimes. For example, we observe that there may be an optimal regularization penalty or training time to avoid bias amplification, and there can be differences in test error between groups that are not alleviated with increased parameterization. Importantly, our theoretical predictions align with  empirical observations reported in the literature on machine learning bias. We extensively empirically validate our theory on synthetic and semi-synthetic datasets.\\nYour task is to identify and elaborate on an insight from the paper. The insight should be self-contained. Write it in a way that doesn’t require referencing where it came from. Do not mention the word \"paper\" or \"document\". Let\\'s think step by step. ',\n",
       " 'paper2_prompt': 'Paper:\\nWe present a Chain-of-Action (CoA) framework for multimodal and retrieval-augmented Question-Answering (QA). Compared to the literature, CoA overcomes two major challenges of current QA applications: (i) unfaithful hallucination that is inconsistent with real-time or domain facts and (ii) weak reasoning performance over compositional information. Our key contribution is a novel reasoning-retrieval mechanism that decomposes a complex question into a reasoning chain via systematic prompting and pre-designed actions.  Methodologically, we propose three types of domain-adaptable `Plug-and-Play\\'  actions for retrieving real-time information from heterogeneous sources. We also propose a multi-reference faith score to verify conflicts in the answers.\\nIn addition, our system demonstrates that detecting the knowledge boundaries of LLMs can significantly reduce both LLM interaction frequency and tokens usage in QA tasks. Empirically, we exploit both public benchmarks and a Web3 case study to demonstrate the capability of CoA over other methods.\\nYour task is to identify and elaborate on an insight from the paper. The insight should be self-contained. Write it in a way that doesn’t require referencing where it came from. Do not mention the word \"paper\" or \"document\". Let\\'s think step by step. ',\n",
       " 'split': 'train'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_train['extra_info'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69cbb819174f46818a9db0545f8f576d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7c42ca1b626448c8edd883f58fe7341",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1764711852"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_train.to_parquet('/home/anikait.singh/rl_behaviors_verl_stable/data_insights_rl/train.parquet')\n",
    "ds_test.to_parquet('/home/anikait.singh/rl_behaviors_verl_stable/data_insights_rl/test.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "verl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
